{
  // Official REST endpoint pattern (SSE):
  //   POST /v1beta/models/{model}:streamGenerateContent?alt=sse
  // Docs: https://ai.google.dev/api
  // Text output model (per repo convention): gemini-3-flash-preview
  endpoint: "/v1beta/models/{model}:streamGenerateContent",
  schemas: {
    response: "gemini.GenerateContentResponse",
    stream_chunk: "gemini.GeminiStreamChunk",
  },
  base_params: {
    contents: [
      {
        role: "user",
        parts: [{ text: "Say hello" }],
      },
    ],
  },
  // Gemini streaming is not SSE-event-typed like OpenAI/Anthropic; validate it by requiring
  // at least one chunk containing candidate text content.
  stream_expectations: {
    min_observations: 1,
    checks: [
      {
        type: "required_field",
        field: "candidates[0].content.parts[0].text",
      },
    ],
  },
  tests: [
    {
      name: "baseline",
      description: "Baseline streaming test: minimal required parameters",
      baseline: true,
      stream: true,
    },
    {
      name: "generationConfig.temperature",
      description: "Test generationConfig.temperature (streaming)",
      stream: true,
      params: { generationConfig: { temperature: 0.7 } },
      focus_param: { name: "generationConfig.temperature", value: 0.7 },
    },
    {
      name: "generationConfig.maxOutputTokens",
      description: "Test generationConfig.maxOutputTokens (streaming)",
      stream: true,
      params: { generationConfig: { maxOutputTokens: 64 } },
      focus_param: { name: "generationConfig.maxOutputTokens", value: 64 },
    },
    {
      name: "generationConfig.topP",
      description: "Test generationConfig.topP (streaming)",
      stream: true,
      params: { generationConfig: { topP: 0.9 } },
      focus_param: { name: "generationConfig.topP", value: 0.9 },
    },
    {
      name: "generationConfig.topK",
      description: "Test generationConfig.topK (streaming)",
      stream: true,
      params: { generationConfig: { topK: 20 } },
      focus_param: { name: "generationConfig.topK", value: 20 },
    },
    {
      name: "generationConfig.candidateCount",
      description: "Test generationConfig.candidateCount (streaming)",
      stream: true,
      params: { generationConfig: { candidateCount: 2 } },
      focus_param: { name: "generationConfig.candidateCount", value: 2 },
    },
    {
      name: "generationConfig.stopSequences",
      description: "Test generationConfig.stopSequences (streaming)",
      stream: true,
      params: { generationConfig: { stopSequences: ["END"] } },
      focus_param: { name: "generationConfig.stopSequences", value: ["END"] },
    },
  ],
}
