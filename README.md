# LLM-Spec

ä¸€ä¸ªè§„èŒƒé©±åŠ¨çš„ LLM API å‚å•†å…¼å®¹æ€§æµ‹è¯•å·¥å…·ï¼Œç”¨äºéªŒè¯å„å‚å•†APIçš„å‚æ•°æ”¯æŒæƒ…å†µå’Œå“åº”æ ¼å¼åˆè§„æ€§ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

- âœ… **ç»†ç²’åº¦å‚æ•°æµ‹è¯•**ï¼šä½¿ç”¨æ§åˆ¶å˜é‡æ³•ï¼Œç²¾ç¡®å®šä½ä¸æ”¯æŒçš„å‚æ•°å’Œå‚æ•°å€¼
- âœ… **å‚æ•°å˜ä½“æµ‹è¯•**ï¼šè‡ªåŠ¨æµ‹è¯•å‚æ•°çš„æ‰€æœ‰å¯èƒ½å€¼ï¼ˆå¦‚ä¸åŒçš„modelã€voiceç­‰ï¼‰
- âœ… **å“åº”æ ¼å¼éªŒè¯**ï¼šä½¿ç”¨Pydanticæ¨¡å‹éªŒè¯å“åº”ç»“æ„ï¼Œå­—æ®µçº§åˆ«é”™è¯¯å®šä½
- âœ… **è¯¦ç»†JSONæŠ¥å‘Š**ï¼šåŒ…å«æµ‹è¯•ç»Ÿè®¡ã€ä¸æ”¯æŒå‚æ•°åˆ—è¡¨ã€ç¼ºå¤±å­—æ®µã€è¯¦ç»†é”™è¯¯ä¿¡æ¯
- âœ… **ç»“æ„åŒ–æ—¥å¿—**ï¼šæ¯ä¸ªè¯·æ±‚æœ‰å”¯ä¸€IDï¼Œå®Œæ•´çš„è¯·æ±‚/å“åº”é“¾è·¯è¿½è¸ª
- âœ… **å¤šProvideræ”¯æŒ**ï¼šæ”¯æŒOpenAIã€Anthropicã€Geminiã€xAIç­‰

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -e ".[dev]"
```

### 2. é…ç½®

ç¼–è¾‘ `llm-spec.toml`ï¼š

```toml
[log]
enabled = true
level = "INFO"
file = "./logs/llm-spec.log"
log_request_body = true
log_response_body = false

[report]
output_dir = "./reports"

[openai]
api_key = "your-api-key"
base_url = "https://api.openai.com"
timeout = 30.0
```

### 3. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œå•ä¸ªendpointæµ‹è¯•
pytest tests/openai/test_chat_completions.py -v

# è¿è¡Œæ‰€æœ‰OpenAIæµ‹è¯•
pytest tests/openai/ -v

# è¿è¡Œæ‰€æœ‰Anthropicæµ‹è¯•
pytest tests/anthropic/ -v

# è¿è¡Œæ‰€æœ‰Geminiæµ‹è¯•
pytest tests/gemini/ -v

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v
```

### 4. æŸ¥çœ‹æŠ¥å‘Š

```bash
# æŠ¥å‘Šè¾“å‡ºä¼šæŒ‰ run_id åˆ†ç›®å½•ï¼ˆä¾‹å¦‚ reports/20260130_123456/...ï¼‰
# å…ˆæ‰¾åˆ°æœ€æ–°çš„ run_id ç›®å½•
ls -lt reports | head

# å†æŸ¥çœ‹æŸä¸ª endpoint çš„ JSON æŠ¥å‘Š
cat reports/<run_id>/openai_v1_chat_completions_*/report.json
```

## ğŸ“‹ é¡¹ç›®ç»“æ„

```
llm-spec/
â”œâ”€â”€ llm_spec/              # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ config/            # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ client/            # HTTPå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ providers/         # Provideré€‚é…å™¨
â”‚   â”œâ”€â”€ validation/        # å“åº”éªŒè¯
â”‚   â””â”€â”€ reporting/         # æŠ¥å‘Šç”Ÿæˆ
â”œâ”€â”€ tests/                 # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ openai/            # OpenAI æµ‹è¯•ï¼ˆ7ä¸ªæ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ anthropic/         # Anthropic æµ‹è¯•ï¼ˆ4ä¸ªæ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ gemini/            # Gemini æµ‹è¯•ï¼ˆ3ä¸ªæ–‡ä»¶ï¼‰
â”‚   â””â”€â”€ xai/               # xAI æµ‹è¯•
â”œâ”€â”€ test_assets/           # æµ‹è¯•èµ„æº
â”œâ”€â”€ reports/               # ç”Ÿæˆçš„æŠ¥å‘Š
â””â”€â”€ logs/                  # æ—¥å¿—æ–‡ä»¶
```

## ğŸš€ æ·»åŠ æ–°çš„ Endpoint æµ‹è¯•

### ç¤ºä¾‹ï¼šæµ‹è¯• `/v1/audio/speech`

1. **åˆ›å»º Pydantic Schema**ï¼ˆå¦‚æœéœ€è¦ï¼‰

```python
# llm_spec/validation/schemas/openai/audio.py
from pydantic import BaseModel

class AudioSpeechResponse(BaseModel):
    # éŸ³é¢‘å“åº”é€šå¸¸æ˜¯äºŒè¿›åˆ¶ï¼Œå¯èƒ½ä¸éœ€è¦éªŒè¯
    pass
```

2. **åˆ›å»ºæµ‹è¯•æ–‡ä»¶**

```python
# tests/providers/openai/test_audio_speech.py
import pytest
from llm_spec.reporting.collector import ReportCollector

class TestAudioSpeech:
    ENDPOINT = "/v1/audio/speech"
    BASE_PARAMS = {
        "model": "tts-1",
        "input": "Hello",
        "voice": "alloy",
    }

    @pytest.fixture(autouse=True)
    def setup_collector(self, openai_client):
        self.client = openai_client
        self.collector = ReportCollector(
            provider="openai",
            endpoint=self.ENDPOINT,
            base_url=openai_client.get_base_url(),
        )
        yield
        self.collector.finalize()

    def test_baseline(self):
        status_code, headers, body = self.client.request(
            endpoint=self.ENDPOINT,
            params=self.BASE_PARAMS,
        )
        self.collector.record_test(
            test_name="test_baseline",
            params=self.BASE_PARAMS,
            status_code=status_code,
            response_body=None,
            error=None if 200 <= status_code < 300 else f"HTTP {status_code}",
        )
        assert 200 <= status_code < 300

    @pytest.mark.parametrize("voice", ["alloy", "echo", "fable"])
    def test_voice_variants(self, voice):
        params = {**self.BASE_PARAMS, "voice": voice}
        status_code, headers, body = self.client.request(
            endpoint=self.ENDPOINT, params=params
        )
        # è®°å½•æµ‹è¯•ç»“æœ...
```

3. **è¿è¡Œæµ‹è¯•**

```bash
pytest tests/providers/openai/test_audio_speech.py -v
```

è¯¦ç»†æ–‡æ¡£è§ [ARCHITECTURE.md](ARCHITECTURE.md)

## ğŸ§ª æµ‹è¯•æ¨¡å¼

### åŸºçº¿æµ‹è¯•
ä»…ä½¿ç”¨å¿…éœ€å‚æ•°ï¼ŒéªŒè¯åŸºæœ¬åŠŸèƒ½

```python
def test_baseline(self):
    params = self.BASE_PARAMS
    # æµ‹è¯•...
```

### å•å‚æ•°æµ‹è¯•
æ¯æ¬¡æµ‹è¯•ä¸€ä¸ªæ–°å‚æ•°ï¼ˆæ§åˆ¶å˜é‡æ³•ï¼‰

```python
def test_param_temperature(self):
    params = {**self.BASE_PARAMS, "temperature": 0.7}
    # å¦‚æœå¤±è´¥ï¼Œè®°å½•ä¸ºä¸æ”¯æŒ
```

### å‚æ•°å˜ä½“æµ‹è¯•
æµ‹è¯•å‚æ•°çš„æ‰€æœ‰å¯èƒ½å€¼

```python
@pytest.mark.parametrize("model", ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"])
def test_model_variants(self, model):
    params = {**self.BASE_PARAMS, "model": model}
    # ç²¾ç¡®æŠ¥å‘Šå“ªä¸ªå€¼ä¸æ”¯æŒ
```

## ğŸ“Š æŠ¥å‘Šæ ¼å¼

ç”Ÿæˆçš„JSONæŠ¥å‘ŠåŒ…å«ï¼š

```json
{
  "test_time": "2026-01-27T15:40:00Z",
  "provider": "openai",
  "endpoint": "/v1/chat/completions",
  "test_summary": {
    "total_tests": 6,
    "passed": 5,
    "failed": 1
  },
  "parameters": {
    "tested": ["model", "messages", "temperature", "max_tokens"],
    "unsupported": [
      {
        "parameter": "model",
        "value": "gpt-4",
        "test_name": "test_model_variants[gpt-4]",
        "reason": "HTTP 404: No available channels"
      }
    ]
  },
  "response_fields": {
    "expected": ["id", "object", "created", "model", "choices"],
    "unsupported": [
      {
        "field": "system_fingerprint",
        "reason": "Field missing in response"
      }
    ]
  },
  "errors": [...]
}
```

## ğŸ¨ è®¾è®¡åŸåˆ™

- **æ˜¾å¼ä¼˜äºéšå¼**ï¼šæ‰€æœ‰å‚æ•°åœ¨æµ‹è¯•ç±»é¡¶éƒ¨æ˜¾å¼å®šä¹‰
- **æ§åˆ¶å˜é‡æ³•**ï¼šæ¯æ¬¡åªæµ‹è¯•ä¸€ä¸ªæ–°å‚æ•°
- **ç»†ç²’åº¦æŠ¥å‘Š**ï¼šç²¾ç¡®åˆ°å‚æ•°å€¼ã€å­—æ®µçº§åˆ«çš„é”™è¯¯
- **ç»Ÿä¸€é”™è¯¯å¤„ç†**ï¼šæ‰€æœ‰é”™è¯¯éƒ½è§†ä¸ºå¤±è´¥å¹¶è®°å½•
- **ä½è€¦åˆé«˜æ‰©å±•**ï¼šæ·»åŠ æ–°endpointæˆ–provideræ— éœ€ä¿®æ”¹æ ¸å¿ƒä»£ç 

## ğŸ“š æ–‡æ¡£

- [ARCHITECTURE.md](ARCHITECTURE.md) - å®Œæ•´æ¶æ„æ–‡æ¡£
- [llm-spec.toml](llm-spec.toml) - é…ç½®æ–‡ä»¶ç¤ºä¾‹

## ğŸ”§ ä¾èµ–

- Python >= 3.11
- httpx - HTTPå®¢æˆ·ç«¯
- pydantic - æ•°æ®éªŒè¯
- pytest - æµ‹è¯•æ¡†æ¶

## ğŸ“ License

MIT
